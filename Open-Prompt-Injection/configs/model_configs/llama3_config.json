{
    "model_info":{
        "provider":"llama3",
        "name":"meta-llama/Meta-Llama-3-8B-Instruct"
    },
    "api_key_info":{
        "api_keys":[0],
        "api_key_use": 0
    },
    "params":{
        "temperature":0.1,
        "seed":100,
        "gpus":["5","6"],
        "device":"cuda",
        "max_output_tokens":150,
        "ft_path":""
    }
}