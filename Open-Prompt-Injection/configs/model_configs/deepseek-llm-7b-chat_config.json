{
    "model_info":{
        "provider":"deepseek",
        "name":"deepseek-ai/deepseek-llm-7b-chat"
    },
    "params":{
        "temperature":0.6,
        "seed":100,
        "gpus":["3","4", "6"],
        "device":"cuda",
        "max_output_tokens":2000,
        "ft_path":""
    }
}